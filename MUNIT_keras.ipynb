{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1910,
     "status": "ok",
     "timestamp": 1524293903328,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "xC1t_giRMc9m",
    "outputId": "69077fdd-07b8-4697-c1fe-0225497e11ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab      edges2shoes.tar.gz     instance_normalization.py  train\r\n",
      "edges2shoes  GroupNormalization.py  __pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIdF4IYi-XiA"
   },
   "source": [
    "### Install/Download Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m3PamTlbMfSk"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/shaoanlu/faceswap-GAN/raw/master/instance_normalization.py\n",
    "!wget https://github.com/shaoanlu/GroupNormalization-keras/raw/master/GroupNormalization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LxViKSycMfOe"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DLUiynFHRKbe"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtoAqMnB-gZR"
   },
   "source": [
    "<a id='1'></a>\n",
    "###  Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5942,
     "status": "ok",
     "timestamp": 1524322752148,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "UPr-tN0L-gZY",
    "outputId": "9a1ba275-72b8-4440-b505-bc64d49404f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.applications import *\n",
    "import keras.backend as K\n",
    "from tensorflow.contrib.distributions import Beta\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_1bvVu9chMK6"
   },
   "outputs": [],
   "source": [
    "from instance_normalization import InstanceNormalization\n",
    "from GroupNormalization import GroupNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oyHeYX2d-gaL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2klmIY2IXwMC"
   },
   "outputs": [],
   "source": [
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1796,
     "status": "ok",
     "timestamp": 1524322760612,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "Pu70Df8D-gac",
    "outputId": "3fc99d50-ab36-4227-a8dc-d91234347967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13456648407330283137, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11288962663\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4753010386747817024\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7IVrZ9n-geE"
   },
   "source": [
    "<a id='4'></a>\n",
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6Hkkpgd4-geI"
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oHkIxhQu-geS"
   },
   "outputs": [],
   "source": [
    "channel_axis=-1\n",
    "channel_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OvbrdD2L-gea"
   },
   "outputs": [],
   "source": [
    "# Architecture configs\n",
    "IMAGE_SHAPE = (128, 128, 3)\n",
    "nc_in = 3 # number of input channels of generators\n",
    "nc_D_inp = 3 # number of input channels of discriminators\n",
    "n_dim_style = 8\n",
    "n_resblocks = 3 # number of residual blocks in decoder and content encoder\n",
    "n_adain = 2*n_resblocks\n",
    "n_dim_adain = 256\n",
    "nc_base = 64 # Number of channels of the first conv2d of encoder\n",
    "n_downscale_content = 2 # Number of content encoder dowscaling\n",
    "n_dowscale_style = 4 # Number of style encoder dowscaling\n",
    "use_groupnorm = False # else use_layer norm in upscaling blocks\n",
    "w_l2 = 1e-4 # L2 weight regularization\n",
    "\n",
    "# Optimization configs\n",
    "use_perceptual_loss = True\n",
    "use_lsgan = True\n",
    "use_mixup = True\n",
    "mixup_alpha = 0.2\n",
    "batchSize = 1\n",
    "conv_init_dis = RandomNormal(0, 0.02) # initializer of dicriminators' conv layers\n",
    "conv_init = 'he_normal' # initializer of generators' conv layers\n",
    "lrD = 1e-4 # Discriminator learning rate\n",
    "lrG = 1e-4 # Generator learning rate\n",
    "opt_decay = 0 # Learning rate decay over each update.\n",
    "lr_decay_step: 100000 # how often to decay learning rate\n",
    "lr_decay: 0.5 # how much to decay learning rate\n",
    "TOTAL_ITERS = 300000 # Max training iterations\n",
    "\n",
    "# Loss weights for generators\n",
    "w_D = 1 # Adversarial loss\n",
    "w_recon = 10 # GT L1 reconstruvtion loss\n",
    "w_recon_latent = 1 # Latent codes L1 reconstruction loss\n",
    "\n",
    "# Path of training images\n",
    "img_dirA = 'train/edges/*.*'\n",
    "img_dirB = 'train/shoes/*.*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0emKOeh-gex"
   },
   "source": [
    "<a id='5'></a>\n",
    "# 5. Define models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CIcpHcB0GUE"
   },
   "source": [
    "#### Encoder_style_MUNIT()\n",
    "  - **Inputs:** input image\n",
    "  - **Outputs:** style code\n",
    "  \n",
    "#### Encoder_content_MUNIT()\n",
    "  - **Inputs:** input image\n",
    "  - **Outputs:** content code\n",
    "  \n",
    "#### MLP_MUNIT()\n",
    "  - **Inputs:** style code\n",
    "  - **Outputs:** adain_params\n",
    "  \n",
    "#### Decoder_MUNIT()\n",
    "  - **Inputs:** (1) style_code, (2) content_code\n",
    "  - **Outputs:** (1) output_image_bgr, (2) style code, (3) content code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1aFM0bR9-gfD"
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Basic Blocks\n",
    "##################################################################################\n",
    "def conv_block(input_tensor, f, k=3, strides=2, use_norm=False):\n",
    "    x = input_tensor\n",
    "    x = ReflectPadding2D(x)\n",
    "    x = Conv2D(f, kernel_size=k, strides=strides, kernel_initializer=conv_init,\n",
    "               kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "               use_bias=(not use_norm), padding=\"valid\")(x)\n",
    "    if use_norm:\n",
    "        x = InstanceNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_d(input_tensor, f, use_norm=False):\n",
    "    x = input_tensor\n",
    "    x = ReflectPadding2D(x)\n",
    "    x = Conv2D(f, kernel_size=4, strides=2, kernel_initializer=conv_init_dis,\n",
    "               kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "               use_bias=(not use_norm), padding=\"valid\")(x)\n",
    "    if use_norm:\n",
    "        x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def upscale_nn(inp, f, use_norm=False):\n",
    "    x = inp\n",
    "    x = UpSampling2D()(x)\n",
    "    x = ReflectPadding2D(x, 2)\n",
    "    x = Conv2D(f, kernel_size=5, kernel_initializer=conv_init, \n",
    "               kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2), \n",
    "               use_bias=(not use_norm), padding='valid')(x)\n",
    "    if use_norm:\n",
    "        if use_groupnorm:\n",
    "            x = GroupNormalization(group=32)(x)\n",
    "        else:\n",
    "            x = GroupNormalization(group=f)(x) # group=f equivalant to layer norm\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "  \n",
    "def ReflectPadding2D(x, pad=1):\n",
    "    x = Lambda(lambda x: tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]], mode='REFLECT'))(x)\n",
    "    return x\n",
    "\n",
    "##################################################################################\n",
    "# Discriminators\n",
    "##################################################################################\n",
    "def Discriminator(nc_in, input_size=IMAGE_SHAPE[0]):\n",
    "    inp = Input(shape=(input_size, input_size, nc_in))\n",
    "    x = conv_block_d(inp, 64, False)\n",
    "    x = conv_block_d(x, 128, False)\n",
    "    x = conv_block_d(x, 256, False)\n",
    "    x = ReflectPadding2D(x, 2)\n",
    "    out = Conv2D(1, kernel_size=5, kernel_initializer=conv_init_dis, \n",
    "                 kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                 use_bias=False, padding=\"valid\")(x)   \n",
    "    return Model(inputs=[inp], outputs=out)\n",
    "\n",
    "def Discriminator_MS(nc_in, input_size=IMAGE_SHAPE[0]):\n",
    "    # Multi-scale discriminator architecture\n",
    "    inp = Input(shape=(input_size, input_size, nc_in))\n",
    "    \n",
    "    def conv2d_blocks(inp, nc_base=64, n_layers=3):\n",
    "        x = inp\n",
    "        dim = nc_base\n",
    "        for _ in range(n_layers):\n",
    "            x = conv_block_d(x, dim, False)\n",
    "            dim *= 2\n",
    "        x = Conv2D(1, kernel_size=1, kernel_initializer=conv_init_dis,\n",
    "                   kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                   use_bias=True, padding=\"valid\")(x)\n",
    "        return x\n",
    "    \n",
    "    x0 = conv2d_blocks(inp)    \n",
    "    ds1 = AveragePooling2D(pool_size=(3, 3), strides=2)(inp)\n",
    "    x1 = conv2d_blocks(ds1)\n",
    "    ds2 = AveragePooling2D(pool_size=(3, 3), strides=2)(ds1)\n",
    "    x2 = conv2d_blocks(ds2)\n",
    "    return Model(inputs=[inp], outputs=[x0, x1, x2])\n",
    "\n",
    "##################################################################################\n",
    "# MUNIT Model Architecture, Encoder\n",
    "##################################################################################    \n",
    "def Encoder_style_MUNIT(nc_in=3, input_size=IMAGE_SHAPE[0], n_dim_adain=256, n_dim_style=n_dim_style, nc_base=nc_base, n_dowscale_style=n_dowscale_style):\n",
    "    # Style encoder architecture \n",
    "    inp = Input(shape=(input_size, input_size, nc_in))\n",
    "    x = ReflectPadding2D(inp, 3)\n",
    "    x = Conv2D(64, kernel_size=7, kernel_initializer=conv_init, \n",
    "               kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "               use_bias=True, padding=\"valid\")(x)\n",
    "    x = Activation('relu')(x)   \n",
    "    \n",
    "    dim = 1\n",
    "    for i in range(n_dowscale_style):\n",
    "        dim = 4 if dim >= 4 else dim*2\n",
    "        x = conv_block(x, dim*nc_base)\n",
    "    x = GlobalAveragePooling2D()(x)    \n",
    "    style_code = Dense(n_dim_style)(x) # Style code\n",
    "    return Model(inp, style_code)\n",
    "\n",
    "def Encoder_content_MUNIT(nc_in=3, input_size=IMAGE_SHAPE[0], n_downscale_content=n_downscale_content, nc_base=nc_base):\n",
    "    # Content encoder architecture \n",
    "    def res_block_content(input_tensor, f):\n",
    "        x = input_tensor\n",
    "        x = ReflectPadding2D(x)\n",
    "        x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, \n",
    "                   kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                   use_bias=False, padding=\"valid\")(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = ReflectPadding2D(x)\n",
    "        x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, \n",
    "                   kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                   use_bias=False, padding=\"valid\")(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = add([x, input_tensor])\n",
    "        return x      \n",
    "    \n",
    "    inp = Input(shape=(input_size, input_size, nc_in))\n",
    "    x = ReflectPadding2D(inp, 3)\n",
    "    x = Conv2D(64, kernel_size=7, kernel_initializer=conv_init, \n",
    "               kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "               use_bias=False, padding=\"valid\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)   \n",
    "    \n",
    "    dim = 1\n",
    "    ds = 2**n_downscale_content\n",
    "    for i in range(n_downscale_content):\n",
    "        dim = 4 if dim >= 4 else dim*2\n",
    "        x = conv_block(x, dim*nc_base, use_norm=True)\n",
    "    for i in range(n_resblocks):\n",
    "        x = res_block_content(x, dim*nc_base)\n",
    "    content_code = x # Content code\n",
    "    return Model(inp, content_code)\n",
    "\n",
    "##################################################################################\n",
    "# MUNIT Model Architecture, Decoder\n",
    "##################################################################################  \n",
    "def MLP_MUNIT(n_dim_style=n_dim_style, n_dim_adain=n_dim_adain, n_blk=3, n_adain=2*n_resblocks):\n",
    "    # MLP for AdaIN parameters\n",
    "    inp_style_code = Input(shape=(n_dim_style,))\n",
    "    \n",
    "    adain_params = Dense(n_dim_adain, activation='relu')(inp_style_code)\n",
    "    for i in range(n_blk - 2):\n",
    "        adain_params = Dense(n_dim_adain, activation='relu')(adain_params)\n",
    "    adain_params = Dense(2*n_adain*n_dim_adain)(adain_params) # No output activation \n",
    "    return Model(inp_style_code, [adain_params])\n",
    "  \n",
    "def Decoder_MUNIT(nc_in=256, input_size=IMAGE_SHAPE[0]//(2**n_downscale_content), n_dim_adain=256, n_resblocks=n_resblocks):\n",
    "    def op_adain(inp):\n",
    "        x = inp[0]\n",
    "        mean, var = tf.nn.moments(x, [1,2], keep_dims=True)\n",
    "        adain_bias = inp[1]\n",
    "        adain_bias = K.reshape(adain_bias, (-1, 1, 1, n_dim_adain))\n",
    "        adain_weight = inp[2]\n",
    "        adain_weight = K.reshape(adain_weight, (-1, 1, 1, n_dim_adain))        \n",
    "        out = tf.nn.batch_normalization(x, mean, var, adain_bias, adain_weight, variance_epsilon=1e-7)\n",
    "        return out\n",
    "      \n",
    "    def AdaptiveInstanceNorm2d(inp, adain_params, idx_adain):\n",
    "        assert inp.shape[-1] == n_dim_adain\n",
    "        x = inp\n",
    "        idx_head = idx_adain*2*n_dim_adain\n",
    "        adain_weight = Lambda(lambda x: x[:, idx_head:idx_head+n_dim_adain])(adain_params)\n",
    "        adain_bias = Lambda(lambda x: x[:, idx_head+n_dim_adain:idx_head+2*n_dim_adain])(adain_params)\n",
    "        out = Lambda(op_adain)([x, adain_bias, adain_weight])\n",
    "        return out\n",
    "      \n",
    "    def res_block_adain(inp, f, adain_params, idx_adain):\n",
    "        x = inp\n",
    "        x = ReflectPadding2D(x)\n",
    "        x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, \n",
    "                   kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                   use_bias=False, padding=\"valid\")(x)\n",
    "        x = Lambda(lambda x: AdaptiveInstanceNorm2d(x[0], x[1], idx_adain))([x, adain_params])     \n",
    "        x = Activation('relu')(x)\n",
    "        x = ReflectPadding2D(x)\n",
    "        x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, \n",
    "                   kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2),\n",
    "                   use_bias=False, padding=\"valid\")(x)\n",
    "        x = Lambda(lambda x: AdaptiveInstanceNorm2d(x[0], x[1], idx_adain+1))([x, adain_params])    \n",
    "        \n",
    "        x = add([x, inp])\n",
    "        return x  \n",
    "    \n",
    "    inp_style = Input((n_dim_style,))\n",
    "    style_code = inp_style\n",
    "    mlp = MLP_MUNIT()\n",
    "    adain_params = mlp(style_code)\n",
    "    \n",
    "    inp_content = Input(shape=(input_size, input_size, nc_in))\n",
    "    content_code = inp_content\n",
    "    x = inp_content\n",
    "    \n",
    "    for i in range(n_resblocks):\n",
    "        x = res_block_adain(x, nc_in, adain_params, 2*i) \n",
    "        \n",
    "    dim = 1\n",
    "    for i in range(n_downscale_content):\n",
    "        dim = dim if nc_in//dim <= 64 else dim*2\n",
    "        # Note: original MUNIT uses layer norm instead of group norm in upscale blocks\n",
    "        x = upscale_nn(x, nc_in//dim, use_norm=True)\n",
    "    x = ReflectPadding2D(x, 3)\n",
    "    out = Conv2D(3, kernel_size=7, kernel_initializer=conv_init, \n",
    "                 kernel_regularizer=regularizers.l2(w_l2), bias_regularizer=regularizers.l2(w_l2), \n",
    "                 padding='valid', activation=\"tanh\")(x)\n",
    "    return Model([inp_style, inp_content], [out, style_code, content_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TSZGJe8w-gfM"
   },
   "outputs": [],
   "source": [
    "encoder_style_A = Encoder_style_MUNIT()\n",
    "encoder_content_A = Encoder_content_MUNIT()\n",
    "encoder_style_B = Encoder_style_MUNIT()\n",
    "encoder_content_B = Encoder_content_MUNIT()\n",
    "decoder_A = Decoder_MUNIT()\n",
    "decoder_B = Decoder_MUNIT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sPBWSC3XXwNI"
   },
   "outputs": [],
   "source": [
    "x = Input(shape=IMAGE_SHAPE) # dummy input tensor\n",
    "netGA = Model(x, decoder_A([encoder_style_A(x), encoder_content_A(x)]))\n",
    "netGB = Model(x, decoder_B([encoder_style_B(x), encoder_content_B(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "at_ala0T-gfS"
   },
   "outputs": [],
   "source": [
    "netDA = Discriminator_MS(nc_D_inp)\n",
    "netDB = Discriminator_MS(nc_D_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olQS3MB1WXVC"
   },
   "source": [
    "### Sanity Check\n",
    "Check if wegihts of `encoder_style`, `encoder_content`, and `decoder` are shown in `netG.trainable_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1446
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1524322777158,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "O8MPZHBV8mGw",
    "outputId": "c565b976-885a-4a49-a364-a409e5dbb312",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoder_content_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1524322778196,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "mjDMJmtKE1ks",
    "outputId": "bfe59e90-1103-4fee-e51a-c03dcb734db4"
   },
   "outputs": [],
   "source": [
    "#encoder_style_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1696
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1524322779298,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "1wF05ZSZE3aY",
    "outputId": "b2191e1b-2bfe-4ada-ef33-24f0721ab1f7"
   },
   "outputs": [],
   "source": [
    "#decoder_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1550,
     "status": "ok",
     "timestamp": 1524322783226,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "IfK9TJgSFHQu",
    "outputId": "3219806d-2018-48c4-ef4f-6ca36c9b6716"
   },
   "outputs": [],
   "source": [
    "#netDB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HJNOB2kbFhI0"
   },
   "outputs": [],
   "source": [
    "assert len(netGB.trainable_weights) == (len(encoder_content_B.trainable_weights) + len(encoder_style_B.trainable_weights) + len(decoder_B.trainable_weights))\n",
    "assert len(netGA.trainable_weights) == (len(encoder_content_A.trainable_weights) + len(encoder_style_A.trainable_weights) + len(decoder_A.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dW76Rzil-gfa"
   },
   "source": [
    "<a id='6'></a>\n",
    "### Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3238,
     "status": "ok",
     "timestamp": 1524322788842,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "As4lugRN-gfc",
    "outputId": "6843b3ed-a177-47ab-df64-59ee24dc7879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights files are successfully loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    encoder_style_A.load_weights(\"models/encoder_style_A.h5\")\n",
    "    encoder_style_B.load_weights(\"models/encoder_style_B.h5\")\n",
    "    encoder_content_A.load_weights(\"models/encoder_content_A.h5\")\n",
    "    encoder_content_B.load_weights(\"models/encoder_content_B.h5\")\n",
    "    decoder_A.load_weights(\"models/decoder_A.h5\")\n",
    "    decoder_B.load_weights(\"models/decoder_B.h5\")\n",
    "    #netGA.load_weights(\"models/netGA.h5\") \n",
    "    #netGB.load_weights(\"models/netGB.h5\") \n",
    "    netDA.load_weights(\"models/netDA.h5\") \n",
    "    netDB.load_weights(\"models/netDB.h5\") \n",
    "    print (\"Model weights files are successfully loaded\")\n",
    "except:\n",
    "    print (\"Error occurs during weights files loading.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tp0L5k5q-gf5"
   },
   "source": [
    "<a id='7'></a>\n",
    "### Define Variables and K.function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5Tm-yC5Y-gf_"
   },
   "outputs": [],
   "source": [
    "def model_paths(netEnc_content, netEnc_style, netDec):\n",
    "    fn_content_code = K.function([netEnc_content.inputs[0]], [netEnc_content.outputs[0]])\n",
    "    fn_style_code = K.function([netEnc_style.inputs[0]], [netEnc_style.outputs[0]])\n",
    "    fn_decoder_rgb = K.function(netDec.inputs, [netDec.outputs[0]])\n",
    "    \n",
    "    fake_output = netDec.outputs[0]   \n",
    "    fn_decoder_out = K.function(netDec.inputs, [fake_output])\n",
    "    return fn_content_code, fn_style_code, fn_decoder_out\n",
    "\n",
    "def translation(src_imgs, style_image, fn_content_code_src, fn_style_code_tar, fn_decoder_rgb_tar, rand_style=False):\n",
    "    # Cross domain translation function\n",
    "    # This funciton is for visualization purpose\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        src_img: source domain images, shape=(input_batch_size, h, w, c)\n",
    "        style_image: target style images,  shape=(input_batch_size, h, w, c)\n",
    "        fn_content_code_src: Source domain K.function of content encoder\n",
    "        fn_style_code_tar: Target domain K.function of style encoder\n",
    "        fn_decoder_rgb_tar: Target domain K.function of decoder\n",
    "        rand_style: sample style codes from normal distribution if set True.\n",
    "    Outputs:\n",
    "        fake_rgb: output tensor of decoder having chennels [R, G, B], shape=(input_batch_size, h, w, c)\n",
    "    \"\"\"\n",
    "    batch_size = src_imgs.shape[0]\n",
    "    content_code = fn_content_code_src([src_imgs])[0]\n",
    "    if rand_style:\n",
    "        style_code = np.random.normal(size=(batch_size, n_dim_style))\n",
    "    elif style_image is None:\n",
    "        style_code = fn_style_code_tar([src_imgs])[0]\n",
    "    else:\n",
    "        style_code = fn_style_code_tar([style_image])[0]\n",
    "    fake_rgb = fn_decoder_rgb_tar([style_code, content_code])[0]\n",
    "    return fake_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8J_V-CSR-ggG"
   },
   "outputs": [],
   "source": [
    "input_A = netGA.inputs[0]\n",
    "input_B = netGB.inputs[0]\n",
    "real_A = Input(shape=(IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))\n",
    "real_B = Input(shape=(IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dEEPr-887kku"
   },
   "outputs": [],
   "source": [
    "path_content_code_A, path_style_code_A, path_decoder_A = model_paths(encoder_content_A, encoder_style_A, decoder_A)\n",
    "path_content_code_B, path_style_code_B, path_decoder_B = model_paths(encoder_content_B, encoder_style_B, decoder_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnLe7sWq-ggP"
   },
   "source": [
    "<a id='8'></a>\n",
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2PBDffrV-ggS"
   },
   "outputs": [],
   "source": [
    "if use_lsgan:\n",
    "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "else:\n",
    "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code for loss functions is borrowed from the original pytorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oz7g8OtLiSGo"
   },
   "outputs": [],
   "source": [
    "# random sampled style code\n",
    "s_a = K.random_normal(shape=(batchSize, n_dim_style), mean=0., stddev=1.)\n",
    "s_b = K.random_normal(shape=(batchSize, n_dim_style), mean=0., stddev=1.)\n",
    "# encode\n",
    "c_a, s_a_prime = encoder_content_A(real_A), encoder_style_A(real_A)\n",
    "c_b, s_b_prime = encoder_content_B(real_B), encoder_style_B(real_B)\n",
    "# decode (within domain)\n",
    "x_a_recon = decoder_A([s_a_prime, c_a])[0]\n",
    "x_b_recon = decoder_B([s_b_prime, c_b])[0]\n",
    "# decode (cross domain)\n",
    "x_ba = decoder_A([s_a, c_b])[0]\n",
    "x_ab = decoder_B([s_b, c_a])[0]\n",
    "# encode again\n",
    "c_b_recon, s_a_recon = encoder_content_A(x_ba), encoder_style_A(x_ba)\n",
    "c_a_recon, s_b_recon = encoder_content_B(x_ab), encoder_style_B(x_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4g4VtcCM-Xlk"
   },
   "outputs": [],
   "source": [
    "# init. losses\n",
    "loss_GA = loss_GB = loss_DA = loss_DB = loss_adv_GA = loss_adv_GB = 0\n",
    "\n",
    "# reconstruction loss\n",
    "loss_x_a_recon = w_recon * K.mean(K.abs(x_a_recon - real_A))\n",
    "loss_x_b_recon = w_recon * K.mean(K.abs(x_b_recon - real_B))\n",
    "loss_s_a_recon = w_recon_latent * K.mean(K.abs(s_a_recon - s_a))\n",
    "loss_s_b_recon = w_recon_latent * K.mean(K.abs(s_b_recon - s_b))\n",
    "loss_c_a_recon = w_recon_latent * K.mean(K.abs(c_a_recon - c_a))\n",
    "loss_c_b_recon = w_recon_latent * K.mean(K.abs(c_b_recon - c_b))\n",
    "loss_GA += (loss_x_a_recon + loss_s_a_recon + loss_c_a_recon)\n",
    "loss_GB += (loss_x_b_recon + loss_s_b_recon + loss_c_b_recon)\n",
    "\n",
    "# GAN loss\n",
    "dist_beta = Beta(mixup_alpha, mixup_alpha)\n",
    "lam_A = dist_beta.sample()\n",
    "mixup_A = lam_A * real_A + (1 - lam_A) * x_ba\n",
    "outputs_DA = netDA(mixup_A)\n",
    "for output in outputs_DA:\n",
    "    loss_DA += loss_fn(output, lam_A * K.ones_like(output))         \n",
    "    loss_adv_GA += w_D * loss_fn(output, (1 - lam_A) * K.ones_like(output)) \n",
    "loss_GA += loss_adv_GA \n",
    "\n",
    "lam_B = dist_beta.sample()\n",
    "mixup_B = lam_B * real_B + (1 - lam_B) * x_ab\n",
    "outputs_DB = netDB(mixup_B)\n",
    "for output in outputs_DB:\n",
    "    loss_DB += loss_fn(output, lam_B * K.ones_like(output))           \n",
    "    loss_adv_GB += w_D * loss_fn(output, (1 - lam_B) * K.ones_like(output))            \n",
    "loss_GB += loss_adv_GB\n",
    "\n",
    "# L2 weight regularization\n",
    "# https://github.com/keras-team/keras/issues/2662\n",
    "# got nan after certain iters?\n",
    "#for loss_tensor in netGA.losses:\n",
    "#    loss_GA += loss_tensor\n",
    "#for loss_tensor in netGB.losses:\n",
    "#    loss_GB += loss_tensor\n",
    "#for loss_tensor in netDA.losses:\n",
    "#    loss_DA += loss_tensor\n",
    "#for loss_tensor in netDB.losses:\n",
    "#    loss_DB += loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18212,
     "status": "ok",
     "timestamp": 1524322820758,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "BQMQM9Gq-Xlo",
    "outputId": "2cdcc47e-11fd-4565-f456-3bfe256508f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# Trainable weights\n",
    "weightsDA = netDA.trainable_weights\n",
    "weightsGA = netGA.trainable_weights\n",
    "weightsDB = netDB.trainable_weights\n",
    "weightsGB = netGB.trainable_weights\n",
    "\n",
    "# Define training function\n",
    "#netDA_train = netGA_train = netDB_train = netGB_train = None # initialize net_train()\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5, decay=opt_decay).get_updates(weightsDA,[],loss_DA)\n",
    "netDA_train = K.function([real_A, real_B],[loss_DA], training_updates)\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5, decay=opt_decay).get_updates(weightsGA,[], loss_GA)\n",
    "netGA_train = K.function([input_A, real_A, real_B], [loss_GA, loss_x_a_recon, loss_s_a_recon, loss_c_a_recon, loss_adv_GA], training_updates)\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5, decay=opt_decay).get_updates(weightsDB,[],loss_DB)\n",
    "netDB_train = K.function([real_B, real_A],[loss_DB], training_updates)\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5, decay=opt_decay).get_updates(weightsGB,[], loss_GB)\n",
    "netGB_train = K.function([input_B, real_B, real_A], [loss_GB, loss_x_b_recon, loss_s_b_recon, loss_c_b_recon, loss_adv_GB], training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_net_train(lr_factor=1.):\n",
    "    global netDA_train, netGA_train, netDB_train, netGB_train\n",
    "\n",
    "    # Define training function\n",
    "    training_updates = Adam(lr=lrD*lr_factor, beta_1=0.5, decay=opt_decay).get_updates(weightsDA,[],loss_DA)\n",
    "    netDA_train = K.function([real_A, real_B],[loss_DA], training_updates)\n",
    "    training_updates = Adam(lr=lrG*lr_factor, beta_1=0.5, decay=opt_decay).get_updates(weightsGA,[], loss_GA)\n",
    "    netGA_train = K.function([input_A, real_A, real_B], [loss_GA, loss_x_a_recon, loss_s_a_recon, loss_c_a_recon, loss_adv_GA], training_updates)\n",
    "\n",
    "    training_updates = Adam(lr=lrD*lr_factor, beta_1=0.5, decay=opt_decay).get_updates(weightsDB,[],loss_DB)\n",
    "    netDB_train = K.function([real_B, real_A],[loss_DB], training_updates)\n",
    "    training_updates = Adam(lr=lrG*lr_factor, beta_1=0.5, decay=opt_decay).get_updates(weightsGB,[], loss_GB)\n",
    "    netGB_train = K.function([input_B, real_B, real_A], [loss_GB, loss_x_b_recon, loss_s_b_recon, loss_c_b_recon, loss_adv_GB], training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybkkbYaN-ghb"
   },
   "source": [
    "### Utils for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MQZpJ_4u-ghq"
   },
   "outputs": [],
   "source": [
    "def showG(test_A, test_B):\n",
    "    imgs_pAtA = np.squeeze(np.array([translation(test_A[i:i+1], None, path_content_code_A, path_style_code_A, path_decoder_A)[0] for i in range(test_A.shape[0])]))\n",
    "    imgs_pBtA = np.squeeze(np.array([translation(test_A[i:i+1], test_B[i:i+1], path_content_code_A, path_style_code_B, path_decoder_B)[0] for i in range(test_A.shape[0])]))\n",
    "    imgs_pBtB = np.squeeze(np.array([translation(test_B[i:i+1], None, path_content_code_B, path_style_code_B, path_decoder_B)[0] for i in range(test_B.shape[0])]))\n",
    "    imgs_pAtB = np.squeeze(np.array([translation(test_B[i:i+1], test_A[i:i+1], path_content_code_B, path_style_code_A, path_decoder_A)[0] for i in range(test_B.shape[0])]))     \n",
    "        \n",
    "    figure_A = np.concatenate([\n",
    "        np.squeeze(test_A),\n",
    "        imgs_pAtA,\n",
    "        imgs_pBtA,\n",
    "        ], axis=-2 )\n",
    "    figure_A = figure_A.reshape(batchSize*IMAGE_SHAPE[0], 3*IMAGE_SHAPE[1], 3)\n",
    "    figure_A = np.clip((figure_A + 1) * 255 / 2, 0, 255).astype('uint8')\n",
    "    figure_B = np.concatenate([\n",
    "        np.squeeze(test_B),\n",
    "        imgs_pBtB,\n",
    "        imgs_pAtB,\n",
    "        ], axis=-2 )\n",
    "    figure_B = figure_B.reshape(batchSize*IMAGE_SHAPE[0], 3*IMAGE_SHAPE[1], 3)\n",
    "    figure_B = np.clip((figure_B + 1) * 255 / 2, 0, 255).astype('uint8')\n",
    "    figure = np.concatenate([figure_A, figure_B], axis=1)\n",
    "    display(Image.fromarray(figure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIr0WL5UF6p4"
   },
   "source": [
    "### Utils for Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p2m7U5Z8F56Q"
   },
   "outputs": [],
   "source": [
    "def get_unit_test_weights(): \n",
    "    # Get the weight values of the first Conv2D layer of encoders, decoders, and discriminators\n",
    "    global encoder_style_A\n",
    "    global encoder_content_A\n",
    "    global encoder_style_B\n",
    "    global encoder_content_B\n",
    "    global decoder_A\n",
    "    global decoder_B\n",
    "    global netDA\n",
    "    global netDB\n",
    "    \n",
    "    w_enc_content_A = encoder_content_A.layers[2].get_weights()\n",
    "    w_enc_style_A = encoder_style_A.layers[2].get_weights()\n",
    "    w_dec_A = decoder_A.layers[3].get_weights()\n",
    "    w_DA = netDA.layers[6].get_weights()\n",
    "    w_enc_content_B = encoder_content_B.layers[2].get_weights()\n",
    "    w_enc_style_B = encoder_style_B.layers[2].get_weights()\n",
    "    w_dec_B = decoder_B.layers[3].get_weights()\n",
    "    w_DB = netDB.layers[6].get_weights()\n",
    "    \n",
    "    return [w_enc_content_A,\n",
    "            w_enc_style_A,\n",
    "            w_dec_A,\n",
    "            w_DA,\n",
    "            w_enc_content_B,\n",
    "            w_enc_style_B,\n",
    "            w_dec_B,\n",
    "            w_DB,\n",
    "           ]\n",
    "\n",
    "def unit_test(prev_weights):\n",
    "    # Test if weights are updated after an iter of training\n",
    "    global encoder_style_A\n",
    "    global encoder_content_A\n",
    "    global encoder_style_B\n",
    "    global encoder_content_B\n",
    "    global decoder_A\n",
    "    global decoder_B\n",
    "    global netDA\n",
    "    global netDB\n",
    "    \n",
    "    w_enc_content_A = encoder_content_A.layers[2].get_weights()\n",
    "    w_enc_style_A = encoder_style_A.layers[2].get_weights()\n",
    "    w_dec_A = decoder_A.layers[3].get_weights()\n",
    "    w_DA = netDA.layers[6].get_weights()\n",
    "    w_enc_content_B = encoder_content_B.layers[2].get_weights()\n",
    "    w_enc_style_B = encoder_style_B.layers[2].get_weights()\n",
    "    w_dec_B = decoder_B.layers[3].get_weights()\n",
    "    w_DB = netDB.layers[6].get_weights()\n",
    "    \n",
    "    name_nets = ['encoder_content_A',\n",
    "                 'encoder_style_A',\n",
    "                 'decoder_A',\n",
    "                 'netDA',\n",
    "                 'encoder_content_B',\n",
    "                 'encoder_style_B',\n",
    "                 'decoder_B',\n",
    "                 'netDB'\n",
    "                ]\n",
    "    \n",
    "    weights = [w_enc_content_A,               \n",
    "               w_enc_style_A,\n",
    "               w_dec_A,\n",
    "               w_DA,\n",
    "               w_enc_content_B,\n",
    "               w_enc_style_B,\n",
    "               w_dec_B,\n",
    "               w_DB,\n",
    "              ]\n",
    "    \n",
    "    print(\"[Unit test]\")\n",
    "    for prev_w, w, net in zip(prev_weights, weights, name_nets):\n",
    "        print(f\"Testing {net}\")\n",
    "        assert (not np.array_equal(prev_w[0], w[0])), f\"Unit test failed! The weights of {net} are exactly the same after a batch of training.\"\n",
    "    \n",
    "    return None    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUcicgNw-gh4"
   },
   "source": [
    "<a id='10'></a>\n",
    "## Start Training\n",
    "\n",
    "Show results and save model weights to `./models` folder every `display_iters` iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1824,
     "status": "ok",
     "timestamp": 1524322825292,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "DciVeUk9-gh7",
    "outputId": "f6671796-f7e7-4caa-f55b-827bc5a1df9c"
   },
   "outputs": [],
   "source": [
    "!mkdir models # create ./models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16788,
     "status": "ok",
     "timestamp": 1524322851106,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "3Om_xT1lXwP-",
    "outputId": "7587758f-b8cb-4cc2-bc41-bb6f57ee6a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 49825 image(s) found.\n",
      "Output directory set to train/shoes/output.\n",
      "Initialised with 49825 image(s) found.\n",
      "Output directory set to train/edge/output."
     ]
    }
   ],
   "source": [
    "pA = Augmentor.Pipeline(\"train/shoes\")\n",
    "print()\n",
    "pB = Augmentor.Pipeline(\"train/edges\")\n",
    "\n",
    "pA.flip_left_right(probability=0.5)\n",
    "pB.flip_left_right(probability=0.5)\n",
    "\n",
    "gA = pA.keras_generator(batch_size=batchSize)\n",
    "gB = pB.keras_generator(batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1524321476628,
     "user": {
      "displayName": "Lu SA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109275333798683015269"
     },
     "user_tz": -480
    },
    "id": "6G7WE3aiU3A4",
    "outputId": "2b923903-8c38-4b66-8e95-1a1e2284905e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "nHhffDPA-giW",
    "outputId": "0864b3c1-4491-4886-d9c2-ff6d067adc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing encoder_content_A...\n",
      "Testing encoder_style_A...\n",
      "Testing decoder_A...\n",
      "Testing netDA...\n",
      "Testing encoder_content_B...\n",
      "Testing encoder_style_B...\n",
      "Testing decoder_B...\n",
      "Testing netDB...\n",
      "Unit test passed.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "gen_iterations = 0\n",
    "errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "errGA_x_recon_sum = errGA_s_recon_sum = errGA_c_recon_sum = 0\n",
    "errGB_x_recon_sum = errGB_s_recon_sum = errGB_c_recon_sum = 0\n",
    "errGA_adv_sum = errGB_adv_sum = 0\n",
    "\n",
    "display_iters = 300\n",
    "lr_factor = 1.\n",
    "\n",
    "while gen_iterations < TOTAL_ITERS: \n",
    "    imgs_A, _ = next(gA) \n",
    "    imgs_A = imgs_A*2 - 1 # transform [0, 1] to [-1, 1]\n",
    "    imgs_B, _ = next(gB) \n",
    "    imgs_B = imgs_B*2 - 1        \n",
    "    \n",
    "    if gen_iterations == 2:\n",
    "        unit_test_weights = get_unit_test_weights()\n",
    "    #elif (gen_iterations) % lr_decay_step == 0:\n",
    "    #    set_net_train(lr_factor)\n",
    "    #    lr_factor *= lr_decay\n",
    "    \n",
    "    # Train dicriminators for one batch\n",
    "    if gen_iterations % 1 == 0:\n",
    "        errDA  = netDA_train([imgs_A, imgs_B])\n",
    "        errDB  = netDB_train([imgs_B, imgs_A])\n",
    "    errDA_sum +=errDA[0]\n",
    "    errDB_sum +=errDB[0]\n",
    "\n",
    "    # Train generators for one batch\n",
    "    errGAs = netGA_train([imgs_A, imgs_A, imgs_B])\n",
    "    errGBs = netGB_train([imgs_B, imgs_B, imgs_A])\n",
    "    errGA_sum += errGAs[0]\n",
    "    errGB_sum += errGBs[0]\n",
    "    errGA_x_recon_sum += errGAs[1]\n",
    "    errGB_x_recon_sum += errGBs[1]\n",
    "    errGA_s_recon_sum += errGAs[2]\n",
    "    errGB_s_recon_sum += errGBs[2]\n",
    "    errGA_c_recon_sum += errGAs[3]\n",
    "    errGB_c_recon_sum += errGBs[3]\n",
    "    errGA_adv_sum += errGAs[4]\n",
    "    errGB_adv_sum += errGBs[4]\n",
    "    \n",
    "    if gen_iterations == 2:\n",
    "        unit_test(unit_test_weights)\n",
    "        print (\"Unit test passed.\")\n",
    "        unit_test_weights = None        \n",
    "    \n",
    "    gen_iterations+=1\n",
    "    \n",
    "    # Visualization\n",
    "    if gen_iterations % display_iters == 0:\n",
    "        clear_output()\n",
    "        print('[Iter. %d] Loss_DA: %f | Loss_DB: %f | Loss_GA: %f | Loss_GB: %f'\n",
    "              % (gen_iterations, errDA_sum/display_iters, errDB_sum/display_iters, \n",
    "                 errGA_sum/display_iters, errGB_sum/display_iters)) \n",
    "        print('[Reconstruction losses (image)] x_a_recon: %f | x_b_recon: %f'\n",
    "              % (errGA_x_recon_sum/display_iters, errGB_x_recon_sum/display_iters))      \n",
    "        print('[Reconstruction losses (style code)] s_a_recon: %f | s_b_recon: %f'\n",
    "              % (errGA_s_recon_sum/display_iters, errGB_s_recon_sum/display_iters))         \n",
    "        print('[Reconstruction losses (content code)] c_a_recon: %f | c_b_recon: %f'\n",
    "              % (errGA_c_recon_sum/display_iters, errGB_c_recon_sum/display_iters))            \n",
    "        print('[Adversarial losses] GA_adv: %f | GB_adv: %f'\n",
    "              % (errGA_adv_sum/display_iters, errGB_adv_sum/display_iters))           \n",
    "        print('[Elapsed time] %f sec.' % (time.time()-t0))   \n",
    "        \n",
    "        for i in range(8//batchSize):\n",
    "            vis_A, _ = gA.send(batchSize) \n",
    "            vis_A = vis_A*2 - 1\n",
    "            vis_B, _ = gB.send(batchSize)\n",
    "            vis_B = vis_B*2 - 1\n",
    "            showG(vis_A, vis_B)          \n",
    "        errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "        errGA_x_recon_sum = errGA_s_recon_sum = errGA_c_recon_sum = 0\n",
    "        errGB_x_recon_sum = errGB_s_recon_sum = errGB_c_recon_sum = 0\n",
    "        errGA_adv_sum = errGB_adv_sum = 0\n",
    "        \n",
    "        # Save models\n",
    "        encoder_style_A.save_weights(\"models/encoder_style_A.h5\")\n",
    "        encoder_content_A.save_weights(\"models/encoder_content_A.h5\")\n",
    "        encoder_style_B.save_weights(\"models/encoder_style_B.h5\")\n",
    "        encoder_content_B.save_weights(\"models/encoder_content_B.h5\")\n",
    "        decoder_A.save_weights(\"models/decoder_A.h5\")\n",
    "        decoder_B.save_weights(\"models/decoder_B.h5\")\n",
    "        #netGA.save_weights(\"models/netGA.h5\")\n",
    "        #netGB.save_weights(\"models/netGB.h5\")\n",
    "        netDA.save_weights(\"models/netDA.h5\")\n",
    "        netDB.save_weights(\"models/netDB.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MUNIT_keras.ipynb",
   "provenance": [
    {
     "file_id": "1CTxCjDNZvgeRp83btdg4zpJ3c1ApcDzh",
     "timestamp": 1523870110404
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
